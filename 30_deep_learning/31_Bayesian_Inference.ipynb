{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning - Bayesian Inference"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "</section><section>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 베이즈 정리(Bayes' Theorem)\n",
    "\n",
    "$$P(A \\cap B) = P(A|B) P(B) = P(B|A) P(A)$$\n",
    "\n",
    "$$P(A|B) = { P(B|A)P(A) \\over P(B) } \\text{, where }P(B) \\ne 0$$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "</section><section>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 베이즈 추론(Bayesian Inference)\n",
    "\n",
    "$$P(H|E) = { P(E|H)P(H) \\over P(E) }$$\n",
    "\n",
    "$H$는 가설(hypothesis), $E$는 증거(evidence)를 의미한다.\n",
    "\n",
    "$P(H)$는 아직 어떠한 증거도 제시되지 않은 상태라는 의미에서 **사전 확률(prior probability)**이라고 한다.\n",
    "\n",
    "$P(H|E)$는 증거 $E$가 관측된 후에 알고자 하는 가설의 확률이라는 의미에서 **사후 확률(posterior probability)**이라고 한다.\n",
    "\n",
    "$P(E|H)$는 가설 $H$가 주어진 후 증거 $E$가 관측될 확률이며, **가능도(likelihood probability)**라고 한다.\n",
    "\n",
    "$$Posterior \\; probability \\propto Likelihood \\times Prior \\; probability$$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "</section><section>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예: 두 사건이 종속(dependent) 사건인 경우\n",
    "\n",
    "|  | P(H) | P(¬H) |  |\n",
    "| :---: | :---: | :---: | :---: |\n",
    "| **P(E)** | 0.4 | 0.2 | 0.6 |\n",
    "| **P(¬E)** | 0.1 | 0.3 | 0.4 |\n",
    "|  | 0.5 | 0.5 | 1.0 |\n",
    "\n",
    "$$P(H) = 0.5$$\n",
    "\n",
    "$$P(H|E) = \\frac {P(E|H)P(H)} {P(E)} = \\frac{0.4 / 0.5\\times 0.5} {0.6} = \\frac{0.4} {0.6} \\approx 67\\%$$\n",
    "\n",
    "$$P(E|H) = \\frac {P(H|E)P(E)} {P(H)} = \\frac{0.4} {0.5} = 80\\%$$\n",
    "\n",
    "$P(H)$는 남자일 확률, $P(E)$는 축구를 좋아할 확률이라고 하자.\n",
    "\n",
    "임의로 선택한 사람이 남자인 경우는 50%(사전 확률)에 불과하지만, 그 사람이 축구를 좋아한다는 증거가 있다면 그 사람이 남자일 확률은 66%(사후 확률)로 증가한다.\n",
    "\n",
    "남자들 중에서 축구를 좋아할 확률은 80%(가능도)이다."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "</section><section>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예: 두 사건이 독립(independent) 사건인 경우\n",
    "\n",
    "|  | P(H) | P(¬H) |  |\n",
    "| :---: | :---: | :---: | :---: |\n",
    "| **P(E)** | 0.01 | 0.09 | 0.10 |\n",
    "| **P(¬E)** | 0.09 | 0.81 | 0.90 |\n",
    "|  | 0.10 | 0.90 | 1.00 |\n",
    "\n",
    "$$P(H) = 0.1$$\n",
    "\n",
    "$$P(H|E) = \\frac {P(E|H)P(H)} {P(E)} = \\frac{0.01 / 0.1 \\times 0.1} {0.1} = \\frac{0.01} {0.1} = 0.1$$\n",
    "\n",
    "$P(H)$는 두번째 숫자가 1일 확률, $P(E)$는 첫번째 숫자가 1일 확률일 때, 두 사건이 독립 사건인 경우에는 사전 확률과 사후 확률의 값이 같다."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "</section><section>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제: 희귀병 검사\n",
    "\n",
    "희귀병에 걸릴 확률이 10%이고, 희귀병 검사의 정확도가 90%일 때, 희귀병 검사에서 양상 판정을 받은 사람이 실제 희귀병에 걸렸을 확률은 얼마인가?\n",
    "\n",
    "$$P(H) = 0.1$$\n",
    "\n",
    "$$P(E | H) = P(\\neg E | \\neg H)= 0.9$$\n",
    "\n",
    "$$P(H \\cap E) = P(E | H) P(H) = 0.9 \\times 0.1 = 0.09$$\n",
    "\n",
    "$$P(\\neg H \\cap \\neg E) = P(\\neg E | \\neg H) P(\\neg H) = 0.9 \\times 0.9 = 0.81$$\n",
    "\n",
    "|  | P(¬E) | P(E) |  |\n",
    "| :---: | :---: | :---: | :---: |\n",
    "| **P(¬H)** | 0.81 | 0.09 | 0.90 |\n",
    "| **P(H)** | 0.01 | 0.09 | 0.10 |\n",
    "|  | 0.82 | 0.18 | 1.00 |\n",
    "\n",
    "\n",
    "$$P(H | E) = \\frac {P(E | H) P(H)} {P(E)} = \\frac{0.9 \\times 0.1} {0.18} = \\frac{0.09} {0.18} = 0.5$$\n",
    "\n",
    "희귀병 검사에서 양상 판정을 받은 사람이 실제 희귀병에 걸렸을 확률은 50%이다."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "</section><section>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제: 공정품질검사\n",
    "\n",
    "물건의 품질불량 발생률이 0.01%이고, 품질불량 검출률이 99%일 때, 품질불량 검출된 물건이 실제 품질 불량일 확률은 얼마인가?\n",
    "\n",
    "$$P(H) = 0.0001$$\n",
    "\n",
    "$$P(E | H) = P(\\neg E | \\neg H)= 0.99$$\n",
    "\n",
    "$$P(H \\cap E) = P(E | H) P(H) = 0.99 \\times 0.0001 = 0.000099$$\n",
    "\n",
    "$$P(\\neg H \\cap \\neg E) = P(\\neg E | \\neg H) P(\\neg H) = 0.99 \\times 0.9999 = 0.989901$$\n",
    "\n",
    "$$P(\\neg H \\cap E) = P(\\neg H) - P(\\neg H \\cap \\neg E) = 0.9999 - 0.989901 = 0.009999$$\n",
    "\n",
    "$$P(E) = P(H \\cap E) + P(\\neg H \\cap E) = 0.000099 + 0.009999 = 0.010098$$\n",
    "\n",
    "$$P(H | E) = \\frac {P(H \\cap E)} {P(E)} = \\frac {0.000099} {0.010098} = 0.009804$$\n",
    "\n",
    "|  | P(¬E) | P(E) |  |\n",
    "| :---: | :---: | :---: | :---: |\n",
    "| **P(¬H)** | 0.989901 | 0.009999 | 0.999900 |\n",
    "| **P(H)** | 0.000001 | 0.000099 | 0.000100 |\n",
    "|  | 0.989902 | 0.010098 | 1.000000 |\n",
    "\n",
    "품질불량으로 검출된 물건 중에서 실제로 품질 불량일 확률은 0.98%이다."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "</section><section>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일일 생산량이 백만개일 경우, 100개의 불량품 중 99개는 검출에 성공하지만 1개는 검출에 실패(미검출; false negative)하며, 9,999개는 과검출(false positive)한다."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "</section><section>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009803921568627472\n",
      "0.09016393442622907\n",
      "0.49999999999999956\n",
      "0.0003364878822363282\n"
     ]
    }
   ],
   "source": [
    "def posterior_prob(prior_prob, likelihood_prob):\n",
    "    H_E = likelihood_prob * prior_prob\n",
    "    NH_NE = likelihood_prob * (1 - prior_prob)\n",
    "    NH_E = 1 - prior_prob - NH_NE\n",
    "    E = H_E + NH_E\n",
    "    return H_E / E\n",
    "\n",
    "print(posterior_prob(0.0001, 0.99))\n",
    "print(posterior_prob(0.001, 0.99))\n",
    "print(posterior_prob(0.01, 0.99))\n",
    "print(posterior_prob(1 - 0.9999966, 0.99))  # Six Sigma"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "</section><section>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최대 가능도 추정(Maximum Likelihood Estimation; MLE)\n",
    "\n",
    "$x_i$를 확률분포에서 수집된 값, $\\theta$를 해당 확률분포의 모수라고 할 때, 주어진 수집 값들이 나올 가능도(likelyhood)를 최대로 만드는 확률분포의 모수를 구하는 방법.\n",
    "\n",
    "$$\\mathcal{L}(\\theta) = f(x_1, x_2, \\cdot\\cdot\\cdot, x_n|\\theta)$$\n",
    "\n",
    "$$\\hat{\\theta} = \\underset{\\theta}{\\mbox{argmax}}  \\mathcal{L}(\\theta)$$\n",
    "\n",
    "$$\\mathcal{L}(\\theta) = \\prod_{i} f(x_i|\\theta) \\text{ if } \\mathbf{X}_i \\text{ is i.i.d.}$$\n",
    "\n",
    "$$\\log\\mathcal{L}(\\theta) = \\sum_i \\log f(x_i|\\theta)$$\n",
    "\n",
    "베이즈 추론과 비교하기 위해 가설($H$)을 모수($\\theta$)로, 증거($E$)를 수집된 값($x$)으로 대체하면,\n",
    "\n",
    "$$P(\\theta|x) = { P(x|\\theta)P(\\theta) \\over P(x) }$$\n",
    "\n",
    "$P(\\theta)$는 사전 확률(prior probability), $P(\\theta|x)$는 사후 확률(posterior probability), $P(x|\\theta)$는 가능도(likelihood probability)이다."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "</section><section>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/mle.png)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "</section><section>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제\n",
    "10 개의 표본 상품의 무게를 측정하였더니 앞의 그래프와 같았다. 상품의 무게 값이 정규 분포를 따를 때 이를 가장 잘 표현하는 확률 분포 곡선은 무엇일까?\n",
    "\n",
    "#### 후보 확률 분포 곡선이 제시되었을 때 풀이 방법:\n",
    "각 확률 분포 곡선에 대해 log likelyhood($\\log\\mathcal{L}(\\theta)$)를 계산하고 이 값이 최대가 되는 확률 분포 곡선을 선택한다. (앞의 그림 참조)\n",
    "\n",
    "#### 후보 확률 분포 곡선이 제시되지 않았을 때 풀이 방법:\n",
    "10 개의 표본 상품의 무게에 대한 평균과 분산을 계산한다. 계산된 값을 평균과 분산으로 갖는 정규 분포 곡선을 그린다. (다음의 평균 및 분산 추정 증명 참조)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "</section><section>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평균 및 분산 추정\n",
    "\n",
    "정규 분포를 따르는 $\\mathbf{X}_i$의 표본 값 $x_i$를 이용하여 원래 분포의 평균과 분산을 추정하라.\n",
    "\n",
    "$$f_{\\mu,\\sigma}(x_i)=\\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp({\\frac{-(x_i-\\mu)^2}{2\\sigma^2})}$$\n",
    "\n",
    "$$\\mathcal{L}(\\theta) =\\prod_{i} f_{\\mu,\\sigma}(x_i)=\\prod_{i} \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp({\\frac{-(x_i-\\mu)^2}{2\\sigma^2})}$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\log\\mathcal{L}(\\theta)&=\\log{\\prod_{i} \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp({\\frac{-(x_i-\\mu)^2}{2\\sigma^2})}} \\\\\n",
    "&=\\sum_{i} \\log{\\frac{1}{\\sqrt{2\\pi}\\sigma} + \\sum_{i} \\exp({\\frac{-(x_i-\\mu)^2}{2\\sigma^2})}} \\\\\n",
    "&= - \\frac {n} {2} \\log {2 \\pi} - n \\log \\sigma - \\frac {1} {2\\sigma^2} \\sum_{i}(x_i-\\mu)^2\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac {\\partial} {\\partial \\mu} \\log\\mathcal{L}(\\theta) &= \\frac {1} {\\sigma^2} \\sum_{i}(x_i-\\mu) \\\\\n",
    "&= \\frac {1} {\\sigma^2}(\\sum_{i} x_i - n\\mu) = 0\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\\therefore \\hat{\\mu} =(\\sum_{i} x_i) / n$$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "</section><section>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac {\\partial} {\\partial \\sigma} \\log\\mathcal{L}(\\theta) = -\\frac {n} {\\sigma} + \\frac {1} {\\sigma^3} \\sum_{i}(x_i-\\mu)^2 = 0$$\n",
    "\n",
    "$$\\therefore \\sigma^2 = \\sum_{i}(x_i - \\mu)^2 / n$$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "</section><section>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최대 사후 확률 추정(Maximum A Posteriori Estimation)\n",
    "\n",
    "베이즈 정리에서\n",
    "\n",
    "$$P(\\theta|x) = { P(x|\\theta)P(\\theta) \\over P(x) }$$\n",
    "\n",
    "$P(\\theta)$는 사전 확률(prior probability), $P(\\theta|x)$는 사후 확률(posterior probability), $P(x|\\theta)$는 가능도(likelihood probability)이다.\n",
    "\n",
    "$$\\hat{\\theta}_{MAP} := \\underset{\\theta}{\\mbox{argmax}} \\frac {P(x|\\theta)P(\\theta)} {P(x)}= \\underset{\\theta}{\\mbox{argmax}} {P(x|\\theta)P(\\theta)}$$\n",
    "\n",
    "$$\\text{cf.: }\\hat{\\theta}_{ML} := \\underset{\\theta}{\\mbox{argmax}} {P(x|\\theta)}$$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "</section><section>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기대값 최대화 알고리즘(Expectation Maximization Algorithm)\n",
    "\n",
    "잠재변수(latent variable)에 의존하는 확률 모델에서 최대 가능도(maximum likelihood) 또는 최대 사후 확률(maximum a posteriori)을 갖는 모수의 추정 값을 찾는 반복 알고리즘이다.\n",
    "\n",
    "통계 모델의 수식을 모르거나 수식의 해를 구할 수 없을 때 사용한다.\n",
    "\n",
    "log likelihood의 기댓값을 계산하는 기댓값(E) 단계와 이 기댓값을 최대화하는 모수 추정값을 구하는 최대화(M) 단계로 나뉜다.\n",
    "\n",
    "첫번째 식의 변수값을 임의로 선택한 후 이 변수값으로 두번째 식의 변수값을 추정한다. 이렇게 구한 변수값으로 다시 첫번째 식의 변수값을 추정하며 이를 반복한다."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "</section><section>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "- https://en.wikipedia.org/wiki/Bayes%27_theorem\n",
    "- https://en.wikipedia.org/wiki/Bayesian_inference\n",
    "- https://en.wikipedia.org/wiki/Maximum_likelihood_estimation\n",
    "- https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation\n",
    "- https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm\n",
    "- https://towardsdatascience.com/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
